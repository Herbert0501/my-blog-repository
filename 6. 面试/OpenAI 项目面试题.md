---
title: 项目面试题2
slug: xiang-mu-mian-shi-ti-2
cover: ""
categories: []
tags: []
halo:
  site: https://blog.kangyaocoding.top
  name: 4dc3f94b-be1c-4c07-8e0b-1a7937e0872e
  publish: false
---
1. 理论依据、2. 方案调研、3. 成熟案例、4. 符合诉求

[工程设计](https://articles.zsxq.com/id_cnp0sxnfmpww.html)
### 1. 你的这个项目的背景和需求来自哪里？

面试官你好。我参与这个项目的主要目标是寻找一个能够真正提升技术实践能力的平台。目前，AI 对话服务在互联网的热门趋势，例如ChatGPT、通义以及文心一言等多样化的模型不断涌现。所以，我想将这些不同的模型整合在一起，以便于使用。基于此，我进行了项目的设计、开发、上线、运维等一系列动作，提高了我的编程能力和技术思维。并且在项目中我所运用的微信对接、登录鉴权、异步接口、下单支付、异步发货、账户管理等应用场景可以运用到其它任何一个项目中使用。所以我选择开发这样一个项目,也为我以后在工作中解决实际场问题，打下了牢固的基础。

>并且此项目运用了DDD分层架构，领域驱动设计实现，对于各个场景都遵守了设计原则和设计模式，解决各类复杂场景的实现。如；生成式服务流程中运用模板模式、策略模式、工厂模式，解决对话过程中所需的规则过滤、模型校验、账户状态、账户扣减等开发流程。

### 2. 项目为什么使用DDD架构，有什么好处？

首先 DDD 的结构分层更加的清晰，与 MVC 相比，避免了 PO、VO 对象被乱用的可能。而则也是在 DDD 中将行为和逻辑封装到一个领域内进行处理，也就是常说的充血模型结果。这样的结构方式，就可以更好的做到业务流程松耦合，功能实现高内聚。

在我的 OpenAI 项目中，按照业务流程涵盖了 `鉴权登录`、`OpenAI对话`、`商品订单`、`微信对接`，四大核心场景，也就是四个核心领域。，每个领域可以独立开发设计、再通过上层进行编排使用。

相比于 MVC 结构，这样的架构设计，不会因为引入更多的功能，系统复杂度也会随着提高。因为所有流程都被拆解了，每个功能都聚合到了自己的领域内，这样复杂度不会增加，也更好维护。

### 3. 充血模型和贫血模型分别合适什么场景？

[DDD 理论基础](https://bugstack.cn/md/road-map/ddd-guide-01.html)

在 DDD 架构中，充血模型主要的价值在于解决具有生命周期的流程。如生成式对话、商品下单支付、用户鉴权登录等流程，因为这些流程中具有较为复杂的场景模型和唯一 ID ，所以采用充血模型结构，也很适合将状态和行为封装到同一领域中进行聚合开发实现。这样的方式，也为以后拓展、迭代、维护奠定了良好的基础，避免工程过于腐化。

而 MVC 架构比较适合 Querys 的场景，因为这些场景只是数据的汇总查询，没有唯一 ID 和生命周期，所以比较适合在工程中提供 query 模块，使用贫血模型开发。

### 4. 项目开发中你是怎么提交代码的？

首先我在 github 仓库中创建了一个空项目地址，之后复制项目地址 `https://****.git` 。然后在本地创建我的项目工程，以及工程中的五个基本模块 (app、domain、infrastructure、tigger、types)。使用 IDEA 的 git 功能创建本地仓库，再把需要的内容进行暂存和提交。最后推送到配置的 git 地址。

在这个过程中还需要将一些不需要提交的文件或者文件夹写进 `.gitignore` 文件中。并且在后续的开发中我还会按照 `时间-姓名-功能` 的规范进行分支的开发，开发完成后进行验证再合并到 `main` 分支中。

### 5. 这个项目有部署上线吗？怎么部署的，部署后内存占用如何，请描述下。

项目上线了，并且对项目进行了 Prometheus + Grafana 监控组件。部署的方式，先购买了 2C4G 的云服务，然后申请了域名并且进行备案了。通过编写 Dockerfile 文件，将前后端项目分别进行打包成镜像，推送到了阿里云仓库。再进行编写 docker-compose.yml 启动文件，在云服务器进行部署启动。由于本项目采用了公众号登录，所以还需要把部署后的服务端的接口地址，配置到微信公众号平台中进行验证码登录。

整个项目部署完成后，占用了50%-60%的服务器内存，Tomcat 配置了最大连接数是250，OpenAI 调用接口的熔断为6秒，但是有时 OpenAI 会超时，所以同时在前端也配置了50秒主动断开。使用 JMeter 压测过接口的响应，目前服务器压测可以50-80 TPS（随着文本的提问量，会有所波动。OpenAI 响应有时候需要6-8秒完成），日常测试接口平均响应值在3-8秒。

为什么有后端有超时熔断，前端也配置50秒主动断开。因为， OpenAI 接口响应是 ResponseBodyEmitter 异步应答，当返回一个数据块后，代表已经有了响应，则不会计算服务端的超时。但第一次应答后，后面的数据卡住了，仍可能一直无应答。所以前端配置了主动超时断开会更稳妥一些。

### 6. 你的项目对接了哪些 OpenAI 接口？怎么对接的？

在目前的项目的开发阶段对接了 ChatGPT 和国内的智普 AI ChatGLM 。它们都有文生文、文生图、多模态的图文理解等功能。对接的方式是采用了会话模型（Mybatis Session）流程，使用 Retrofit2 + Okhttp3 框架，封装 OpenAI Http 接口。提供统一的出入参，并使用工厂模式，构建 OpenAI 启动阶段所需要的验证、日志、执行流程。最终对外提供了 OpenAI 对话服务。

### 7. 因为你的项目是前后端分离的，接口跨域怎么做的？

首先我们知道，Web 跨域（Cross-Origin Resource Sharing，CORS）是一种安全机制，用于限制一个域下的文档或者脚本如何与另一个源的资源进行交互，这是一个浏览器强制执行的安全特性，主要为了防止恶意网站读取或修改另一个网站的数据。

所以我在我的前后端分离项目中，通过配置 @CrossOrigin 注解来解决跨域问题。在开发阶段使用 `Access-Control-Allow-Origin: *`，上线后使用自己的域名来替代。

### 8. 请描述下商品下单支付场景。以及怎么保证的补偿。

下单支付场景在整个项目中也是一块非常核心的流程。首先系统设计采用了 DDD 架构，对商品下单按照业务流程拆解出来了单独的领域模块。在设计实现上，以购物车为下单实体对象，出参为支付单实体对象，保存的是订单的聚合信息。

由于下单是一个较为复杂的流程，所以在编码实现上采用了模板模式，定义出下单的标准过程。商品下单的流程需要先查询是否存在 `已下单未支付` 和 `已下单但未存在支付单`的订单，对于这两种订单分别进行处理。对于已下单未支付，在有效期内未关单的，直接返回给用户直接支付。对于已下单但未存在支付单的，则调用微信支付创建订单，保存库表记录后返回给客户端用户进行支付。此外的流程则直接执行购物车的商品 ID 查询、组装聚合订单数据、创建支付单、保存库表记录、返回给用户。在用户支付完成后，接收支付回调信息，发送 Google Guava 事件信息，由系统中 tigger 模块下的监听处理支付成功消息的方法执行，完成商品订单发货处理。

然后在处理接收回调消息的时候可能会失败。这个时候则由定时任务扫描库表订单超过15分钟的未支付的订单，查询支付平台是否已经支付，如果支付了，则发送事件消息走补货的流程。另外如果超过15分钟以上未支付则进行本地关单处理，不对平台进行关单（因为平台有自己的关单时间），这样可以让用户体验更加舒服。如果用户超时后再进行支付，也可以走补货的流程。（但如果用户刷新界面，则获取创建新的支付单。）

**补充**：怎么实现的定时任务？如果同时有很多任务同一时间待处理怎么办？

**答**：在我的项目中，我使用的是 Spring 框架提供的 @Scheduled 注解来处理定时任务。它可以通过 `fixedRate`、`fixedDelay`、`cron`表达式等方式来灵活配置任务的执行周期。相比于 Timer 或者 ScheduledExecutorService，使用它更加方便，因为它不要显示的创建和管理线程池，Spring 会自动处理任务的调度和线程管理。

**补充**：如果存在多个定时任务的同时等待执行，怎么处理？

**答**：
1.我们可以在配置文件中配置`TaskScheduler`或使用 `@EnableScheduling`与自定义的`ThreadPoolTaskScheduler`，保证多个定时任务并发执行不会阻塞其他任务。
2.根据业务要求我们可以设置优先级，例如采用`PriorityBlockingQueue`来存储任务，根据任务的优先级来依次执行。
3.如果业务容忍一定的延迟执行的话，可以采用异步任务调度，可以通过消息队列（RabbitMQ、Kafka等）来调度任务，让任务以事件驱动的方式执行，而不是同步处理所有任务。


### 9. 你的订单表也是一个频繁使用的表，那么库表有哪些核心字段，索引有哪些？

核心的字段： 用户ID、商品ID、商品名称、商品额度、可用模型、订单ID、下单时间、订单状态、订单金额、支付方式、支付链接、支付金额、交易单号、支付状态、支付时间。其中，对表中的订单ID和用户ID作了唯一索引。对下单时间、订单状态、支付状态做了复合索引，如统计特定时间段内的订单状态和支付情况。

### 10. 我看到OpenAI的体验，都是渐进式展示的，这块后端使用了什么接口形式？

这部分使用的是 SpringBoot 应用提供的 Http 接口，返回的是 ResponseBodyEmitter 异步请求处理协议。它是 SpringMVC 提供的一个异步响应，当控制器中返回一个 ResponseBodyEmitter 实例时，SpringMVC 会开启一个异步请求处理，这样就可以在单个请求中发送多个 OpenAI 应答数据块。这样的应答方式非常适合处理 OpenAI 这样需要大批量应答数据的场景。

由于服务端接口需要 Nginx 转发，所以在 Nginx 端口还需要关闭分块解码、关闭转发缓存、关闭应答缓存，这样展示了一个渐进式的效果。

### 11. 你的项目中对接了 ChatGPT 和 ChatGLM 两个模型，那么使用了什么设计模式？

关于多个模型服务，在项目中定义了一个通信渠道策略接口，接口方法返回统一的格式数据。多款 OpenAI 服务分别实现自己的接口处理。之后多个实现的策略模式注入到 Map 中，Key 是一个枚举值。当服务器选择不同的模型进行问答时，就会根据模型的枚举值，从中选择对应的策略处理类。这样也方便了后续更多模型的拓展。

**补充**：对话的历史上下文数据你是怎么传过去的？怎么界定传多少消息过去呢？如果传的消息内容太多超过大模型记忆窗口会发生什么呢？你对话的历史数据是存到哪的，有什么办法提高查询效率吗？

**答**：
1.目前是不保留用户信息的，通过前端浏览器存储，后面携带历史记录进行消息传递（有最大上限条数为5，整体性能可以）。
2.如果需要动态调整的话，可以考虑计算每条消息占用的 token 数量，控制传递消息的总 token 数不超过模型的窗口大小，比如 GPT3.5，限制 token 为 16385 ，那我们要确保消息不会超出这个值。
如果消息的内容太多的话，可以考虑对旧的数据进行摘要处理，减少总 token 数量。
3.如果超出模型的 token 窗口大小，超出的部分会被截断，无法被模型处理。可能导致模型无法理解上下文，影响答复的质量。
4.**分批处理**：历史数据较多，采用分批次传递。**提示用户**：告知用户历史对话数已超过 Context window 大小，旧的数据将被忽略掉 / 请开启新的对话来更好的体验。
5.对话的历史数据如果要持久化的话，当用户活跃在某个对话窗口时，我们可以将对话信息以 Hash 的结构来存储在 Redis 中。当用户不活跃（离开界面）时，就异步的将数据存放到 MySQL 中进行持久化，然后将对话记录也同步到 ES 中来提高搜索性能。
6.保底方案就是在总用户最不活跃的时间段，定时任务处理持久化消息。

### 12. 你在项目中有支付购买的次数，那么对应就会有额度扣减、账户的校验、还有模型的使用类型，这些是怎么实现的？

> 工厂模式：定义一个接口用于创建对象，但让子类决定实例化哪个类。

其实除了账户、额度、模型，还有敏感词过滤，这部分的实现我定义了统一的 ILogicFilter 过滤接口，并且分别实现了不同的过滤需求。通过 DefaultLogicFactory 类工厂的封装，使用 Map 装配不同的过滤规则类。用户进行问答后，会对用户的的信息分别进行校验。这部分也是整体 OpenAI 应答中使用的模板、工厂、策略三个设计模式。

关于敏感词的处理，对接的是通用的敏感词库，但是校验的过于严格同时不是动态的，所以可能不够准确。后续会采用云服务商提供的敏感词过滤服务。可以配置广告、舆论、情感类等可以配置过滤。

### 13. 你是怎么处理异常的？

项目在对接 OpenAI 接口、数据库、缓存、下单调用等，是可能会出现超时、数据接口更新、数据库连接、缓存时间问题等异常，这些属于功能异常，是在每个模型内可能发送的问题情况。为了异常务保持统一，所以在 types 层中定义了业务异常类 ChatAIException 和对应的异常码枚举（0000成功，0001失败，0002非法参数，0003未登录，0E001商品下架等异常码）这样就可以标准化返回给前端。

### 14. 对于返回给前端的接口，返回从出参结果怎么定义的？

定义一个 `Response<T> `添加 code、info、data （枚举类型）参数，统一封装返回结果。这是一个通用的设计，许多开发的系统也是这样统一标准接口出参的。

### 15. 公众号里可以对接 OpenAI 自动回复吗？

技术上可以对接的，在公众号配置完接口地址验签成功后，就可以接收用户在公众号发送的消息了，之后根据消息的内容请求 OpenAI 接口。但是，如果是个人公众号开发，不能根据用户 ID 返回信息，只能随着请求一次返回。

还有可能用户提问后，调用 OpenAI 接口，因为会需要较长时间的返回数据，超过了公众号5秒限制，就会得不到数据，所以这里利用公众号回调机制，5秒+3次，我在后端使用 CountDownLatch 进行等待，每次都耗时5秒，让公众号第3次在从我的后端获取数据返回。这样可以最大限度保证一次提问就能获得数据。如果还没有获得到数据，这提示给用户需要再次输入一样的问题，以这个问题作为 Key ，获取 OpenAI 的结果缓存返回给用户。

### 16. 应用程序使用了什么数据库连接池，连接数配置如何？

在我的项目中，配置了 SpringBoot 默认的 hikari 连接池。

配置了最小空闲连接数是15个，最大连接数是25个。本身接口的平均响应时间是48ms，那么 `1秒 / 0.048秒/事务 = 约20.83事务/秒/连接`，也就是 `20.83事务/秒/连接 * 25连接 = 约520.75事务/秒`
这个量级是非常够用了。如果不够的话，可以适当上调连接数的大小。

### 17. 是否支持分布式部署？

是支持分布式部署的。一个项目是否支持分布式部署的标识在于它的数据处理是否基于单体还是基于分布式架构的，当一台机器宕机，用户在访问的时候轮询到下一台机器是否还可以保证业务进行。

像我的项目，使用的是MySQL数据库存储用户、账户、商品、订单，在 Redis 存放用户的登录鉴权，那么就可以基于 Nginx 轮询的方式配置多态应用负载，以支持分布式架构。

### 18. 登录这个业务过程是什么样？

企业公众号登录的模型是通过 AccessToken 创建二维码凭证 ticket，并让前端根据凭证创建带参登录二维码。

但是，由于是个人开发，所以我使用的是个人公众号，所以只能是让用户在公众号中回复一个固定的标识消息来获取验证码（类似邮箱登录），之后服务端接收固定的标识后，创建一个唯一登录验证码分配给用户openid，用户通过输入验证码的方式进行登录，最后调用服务端接口进行鉴权并下发 Jwt Token ，实现了登录。

### 19. 如果现在需要让你扩展一个功能，比如接入图片转代码/根据流程图生成代码你会怎么做？

先去了解需要对接功能的文档【技术调研】，之后结合文档来做对应的案例，让案例覆盖80%要实现的功能。这样你大概知道了这样东西是可以使用的。

接下来梳理代码，设计接入方式和流程，并设计这部分的领域功能，开发完成功能以后开始进行测试验证。

测试通过后，开始提供对应的服务的接口，如果是旧的功能扩展，则要考虑兼容性，比如增加了新的模型枚举。

### 20.（开放问题）你在做项目中，什么问题难住你的时间最长，为什么？

第一个：

关于对话时的规则过滤的问题，如额度、白名单、模型等进行过滤。刚开始想如果设计为`if else`的话那就不好维护和拓展，于是通过上网搜索简单的学习了一下工厂模式，通过工厂模式进行装配不同的过滤规则，实现了规则过滤。

第二个：

关于下单的场景问题，由于没有解除过支付项目，不清楚到底以什么作为入参，什么作为出参，经过了大量的网上搜索和思考，得出大概的理解，以超市购买东西为例，我推着购物车到收银台，创建支付订单，扫码支付。

所以在系统设计上，以购物车作为入参实体，出参为支付单信息，中间的流程使用聚合对象保存订单信息。这样设计比较清晰、便于维护。

## 其他

### 1. 为什么要使用 OkHttp3 和 Retrofit ？

对于 http 的封装调用，我了解的有，Apache HttpClient、OkHttp、Retrofit、以及hutool 也提供了封装框架。

而我项目中使用这两个框架的主要原因是：

1. OkHttp 是一个现代的 HTTP 客户端，提供了比较简便的 API 和高效的性能。它支持同步阻塞调用和异步调用，并且可以处理 SPDY、HTTP/2 和 WebSocket 等协议。
2. Retrofit 是一个类型安全的 HTTP 客户端，它通过注解将 HTTP API 转为 Java 接口。它通常与 OkHttp 一起使用，提供了一个更高层次的抽象来处理网络请求。
3. 目前在微信支付 SDK 、支付宝 SDK 都有在使用 OkHttp 框架，对于一下标准度更高的调用，则使用 Retrofit ，因为它通过简单配置就可以使用，屏蔽了对接的细节。这和以前的 HttpClinet 对接方式相比更加简洁，维护成本更低。